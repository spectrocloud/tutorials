{"metadata":{"name":"docs-ubuntu-k3s","description":"Cluster profile as part of the edge cluster deployment tutorial.","labels":{"app":"hello-universe","spectro-cloud-education":"spectro__tag","terraform_managed":"false"}},"spec":{"version":"1.0.0","template":{"type":"cluster","cloudType":"edge-native","packs":[{"name":"edge-native-byoi","type":"spectro","layer":"os","version":"1.0.0","tag":"1.0.0","values":"pack:\n  content:\n    images:\n      - image: \"{{.spectro.pack.edge-native-byoi.options.system.uri}}\"\n    #drain:\n    #cordon: true\n    #timeout: 60 # The length of time to wait before giving up, zero means infinite\n    #gracePeriod: 60 # Period of time in seconds given to each pod to terminate gracefully. If negative, the default value specified in the pod will be used\n    #ignoreDaemonSets: true\n    #deleteLocalData: true # Continue even if there are pods using emptyDir (local data that will be deleted when the node is drained)\n    #force: true # Continue even if there are pods that do not declare a controller\n    #disableEviction: false # Force drain to use delete, even if eviction is supported. This will bypass checking PodDisruptionBudgets, use with caution\n    #skipWaitForDeleteTimeout: 60 # If pod DeletionTimestamp older than N seconds, skip waiting for the pod. Seconds must be greater than 0 to skip.\n\noptions:\n  system.uri: \"{{ .spectro.pack.edge-native-byoi.options.system.registry }}/{{ .spectro.pack.edge-native-byoi.options.system.repo }}:{{ .spectro.pack.edge-native-byoi.options.system.k8sDistribution }}-{{ .spectro.system.kubernetes.version }}-{{ .spectro.pack.edge-native-byoi.options.system.peVersion }}-{{ .spectro.pack.edge-native-byoi.options.system.customTag }}\"\n  system.registry: ttl.sh\n  system.repo: ubuntu\n  system.k8sDistribution: k3s\n  system.osName: ubuntu\n  system.peVersion: v3.4.3\n  system.customTag: demo\n  system.osVersion: 22","registry":{"metadata":{"uid":"5eecc89d0b150045ae661cef","name":"Public Repo","kind":"pack","isPrivate":false}}},{"name":"edge-k3s","type":"spectro","layer":"k8s","version":"1.25.2","tag":"1.25.x","values":"cluster:\n  config: |\n    # disable the built in cni\n    flannel-backend: none\n    no-flannel: true\n    disable-network-policy: true\n    disable:\n      - traefik\n      - local-storage\n      - servicelb\n      - metrics-server\n    \n    # configure the pod cidr range\n    cluster-cidr: \"192.168.0.0/16\"\n    \n    # configure service cidr range\n    service-cidr: \"192.169.0.0/16\"\n    \n    # kubeconfig must be in run for the stylus operator to manage the cluster\n    write-kubeconfig: /run/kubeconfig\n    write-kubeconfig-mode: 600\n    \n    # additional component settings to harden installation\n    kube-apiserver-arg:\n      - anonymous-auth=true\n      - profiling=false\n      - disable-admission-plugins=AlwaysAdmit\n      - default-not-ready-toleration-seconds=60\n      - default-unreachable-toleration-seconds=60\n      - enable-admission-plugins=AlwaysPullImages,NamespaceLifecycle,ServiceAccount,NodeRestriction\n      - audit-log-path=/var/log/apiserver/audit.log\n      - audit-policy-file=/etc/kubernetes/audit-policy.yaml\n      - audit-log-maxage=30\n      - audit-log-maxbackup=10\n      - audit-log-maxsize=100\n      - authorization-mode=RBAC,Node\n      - tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\n    kube-controller-manager-arg:\n      - profiling=false\n      - terminated-pod-gc-threshold=25\n      - pod-eviction-timeout=1m0s\n      - use-service-account-credentials=true\n      - feature-gates=RotateKubeletServerCertificate=true\n    kube-scheduler-arg:\n      - profiling=false\n    kubelet-arg:\n      - read-only-port=0\n      - event-qps=0\n      - feature-gates=RotateKubeletServerCertificate=true\n      - protect-kernel-defaults=true\n      - tls-cipher-suites=TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_256_GCM_SHA384,TLS_RSA_WITH_AES_128_GCM_SHA256\n\nstages:\n  initramfs:\n    - sysctl:\n        vm.overcommit_memory: 1\n        kernel.panic: 10\n        kernel.panic_on_oops: 1\n        kernel.printk: \"0       4       0       7\"\n    - directories:\n        - path: \"/var/log/apiserver\"\n          permissions: 0644\n      files:\n        - path: /etc/hosts\n          permission: \"0644\"\n          content: |\n            127.0.0.1 localhost\n        - path: \"/etc/kubernetes/audit-policy.yaml\"\n          owner_string: \"root\"\n          permission: 0600\n          content: |\n            apiVersion: audit.k8s.io/v1\n            kind: Policy\n            rules:\n              - level: None\n                users: [\"system:kube-proxy\"]\n                verbs: [\"watch\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"endpoints\", \"services\", \"services/status\"]\n              - level: None\n                users: [\"system:unsecured\"]\n                namespaces: [\"kube-system\"]\n                verbs: [\"get\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"configmaps\"]\n              - level: None\n                users: [\"kubelet\"] # legacy kubelet identity\n                verbs: [\"get\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"nodes\", \"nodes/status\"]\n              - level: None\n                userGroups: [\"system:nodes\"]\n                verbs: [\"get\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"nodes\", \"nodes/status\"]\n              - level: None\n                users:\n                  - system:kube-controller-manager\n                  - system:kube-scheduler\n                  - system:serviceaccount:kube-system:endpoint-controller\n                verbs: [\"get\", \"update\"]\n                namespaces: [\"kube-system\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"endpoints\"]\n              - level: None\n                users: [\"system:apiserver\"]\n                verbs: [\"get\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"namespaces\", \"namespaces/status\", \"namespaces/finalize\"]\n              - level: None\n                users: [\"cluster-autoscaler\"]\n                verbs: [\"get\", \"update\"]\n                namespaces: [\"kube-system\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"configmaps\", \"endpoints\"]\n              # Don't log HPA fetching metrics.\n              - level: None\n                users:\n                  - system:kube-controller-manager\n                verbs: [\"get\", \"list\"]\n                resources:\n                  - group: \"metrics.k8s.io\"\n              # Don't log these read-only URLs.\n              - level: None\n                nonResourceURLs:\n                  - /healthz*\n                  - /version\n                  - /swagger*\n              # Don't log events requests.\n              - level: None\n                resources:\n                  - group: \"\" # core\n                    resources: [\"events\"]\n              # node and pod status calls from nodes are high-volume and can be large, don't log responses for expected updates from nodes\n              - level: Request\n                users: [\"kubelet\", \"system:node-problem-detector\", \"system:serviceaccount:kube-system:node-problem-detector\"]\n                verbs: [\"update\",\"patch\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"nodes/status\", \"pods/status\"]\n                omitStages:\n                  - \"RequestReceived\"\n              - level: Request\n                userGroups: [\"system:nodes\"]\n                verbs: [\"update\",\"patch\"]\n                resources:\n                  - group: \"\" # core\n                    resources: [\"nodes/status\", \"pods/status\"]\n                omitStages:\n                  - \"RequestReceived\"\n              # deletecollection calls can be large, don't log responses for expected namespace deletions\n              - level: Request\n                users: [\"system:serviceaccount:kube-system:namespace-controller\"]\n                verbs: [\"deletecollection\"]\n                omitStages:\n                  - \"RequestReceived\"\n              # Secrets, ConfigMaps, and TokenReviews can contain sensitive \u0026 binary data,\n              # so only log at the Metadata level.\n              - level: Metadata\n                resources:\n                  - group: \"\" # core\n                    resources: [\"secrets\", \"configmaps\"]\n                  - group: authentication.k8s.io\n                    resources: [\"tokenreviews\"]\n                omitStages:\n                  - \"RequestReceived\"\n              # Get repsonses can be large; skip them.\n              - level: Request\n                verbs: [\"get\", \"list\", \"watch\"]\n                resources:\n                  - group: \"\" # core\n                  - group: \"admissionregistration.k8s.io\"\n                  - group: \"apiextensions.k8s.io\"\n                  - group: \"apiregistration.k8s.io\"\n                  - group: \"apps\"\n                  - group: \"authentication.k8s.io\"\n                  - group: \"authorization.k8s.io\"\n                  - group: \"autoscaling\"\n                  - group: \"batch\"\n                  - group: \"certificates.k8s.io\"\n                  - group: \"extensions\"\n                  - group: \"metrics.k8s.io\"\n                  - group: \"networking.k8s.io\"\n                  - group: \"policy\"\n                  - group: \"rbac.authorization.k8s.io\"\n                  - group: \"settings.k8s.io\"\n                  - group: \"storage.k8s.io\"\n                omitStages:\n                  - \"RequestReceived\"\n              # Default level for known APIs\n              - level: RequestResponse\n                resources:\n                  - group: \"\" # core\n                  - group: \"admissionregistration.k8s.io\"\n                  - group: \"apiextensions.k8s.io\"\n                  - group: \"apiregistration.k8s.io\"\n                  - group: \"apps\"\n                  - group: \"authentication.k8s.io\"\n                  - group: \"authorization.k8s.io\"\n                  - group: \"autoscaling\"\n                  - group: \"batch\"\n                  - group: \"certificates.k8s.io\"\n                  - group: \"extensions\"\n                  - group: \"metrics.k8s.io\"\n                  - group: \"networking.k8s.io\"\n                  - group: \"policy\"\n                  - group: \"rbac.authorization.k8s.io\"\n                  - group: \"settings.k8s.io\"\n                  - group: \"storage.k8s.io\"\n                omitStages:\n                  - \"RequestReceived\"\n              # Default level for all other requests.\n              - level: Metadata\n                omitStages:\n                  - \"RequestReceived\"","registry":{"metadata":{"uid":"5eecc89d0b150045ae661cef","name":"Public Repo","kind":"pack","isPrivate":false}}},{"name":"cni-calico","type":"spectro","layer":"cni","version":"3.25.1","tag":"3.25.x","values":"pack:\n  content:\n    images:\n      - image: gcr.io/spectro-images-public/calico/cni:v3.25.1\n      - image: gcr.io/spectro-images-public/calico/node:v3.25.1\n      - image: gcr.io/spectro-images-public/calico/kube-controllers:v3.25.1\n\nmanifests:\n  calico:\n\n    # IPAM type to use. Supported types are calico-ipam, host-local\n    ipamType: \"calico-ipam\"\n\n    calico_ipam:\n      assign_ipv4: true\n      assign_ipv6: false\n\n    # Should be one of CALICO_IPV4POOL_IPIP or CALICO_IPV4POOL_VXLAN  \n    encapsulationType: \"CALICO_IPV4POOL_IPIP\"\n\n    # Should be one of Always, CrossSubnet, Never\n    encapsulationMode: \"Always\"\n\n    env:\n      # Additional env variables for calico-node\n      calicoNode:\n        #IPV6: \"autodetect\"\n        #FELIX_IPV6SUPPORT: \"true\"\n        #CALICO_IPV6POOL_NAT_OUTGOING: \"true\"\n        #CALICO_IPV4POOL_CIDR: \"192.168.0.0/16\"\n        #IP_AUTODETECTION_METHOD: \"first-found\"\n\n      # Additional env variables for calico-kube-controller deployment\n      calicoKubeControllers:\n        #LOG_LEVEL: \"info\"\n        #SYNC_NODE_LABELS: \"true\"","registry":{"metadata":{"uid":"5eecc89d0b150045ae661cef","name":"Public Repo","kind":"pack","isPrivate":false}}},{"name":"hello-universe","type":"manifest","layer":"addon","version":"1.0.0","values":"pack:\n  spectrocloud.com/install-priority: \"0\"","registry":{"metadata":{"uid":"","name":"","kind":"","isPrivate":false}},"manifests":[{"name":"hello-universe","content":"apiVersion: v1\nkind: Service\nmetadata:\n  name: hello-universe-service\nspec:\n  type: NodePort\n  selector:\n    app: hello-universe\n  ports:\n  - protocol: TCP\n    port: 8080\n    targetPort: 8080\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello-universe-deployment\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-universe\n  template:\n    metadata:\n      labels:\n        app: hello-universe\n    spec:\n      containers:\n      - name: hello-universe  \n        image: ghcr.io/spectrocloud/hello-universe:1.0.12 \n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 8080"}]}]}}}