pack:
    content:
        images:
            - image: gcr.io/spectro-images-public/release/spectro-vm-dashboard:4.4.10
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-operator:v1.2.0
            - image: registry.k8s.io/sig-storage/snapshot-validation-webhook:v6.3.4
            - image: registry.k8s.io/sig-storage/snapshot-controller:v6.3.4
            - image: ghcr.io/k8snetworkplumbingwg/multus-cni:v4.0.2-thick
            - image: ghcr.io/k8snetworkplumbingwg/multus-dynamic-networks-controller:latest-amd64
            - image: quay.io/kubevirt/cdi-operator:v1.58.0
            - image: quay.io/kubevirt/cdi-uploadproxy:v1.58.0
            - image: quay.io/kubevirt/cdi-controller:v1.58.0
            - image: quay.io/kubevirt/cdi-apiserver:v1.58.0
            - image: quay.io/kubevirt/cdi-importer:v1.58.0
            - image: quay.io/kubevirt/cdi-uploadserver:v1.58.0
            - image: quay.io/kubevirt/cdi-cloner:v1.58.0
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-handler:v1.2.0
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-launcher:v1.2.0
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-exportproxy:v1.2.0
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-exportserver:v1.2.0
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-controller:v1.2.0
            - image: gcr.io/spectro-images-public/release/kubevirt/virt-api:v1.2.0
            - image: registry.k8s.io/descheduler/descheduler:v0.30.1
            - image: gcr.io/spectro-images-public/release/virtual-machine-orchestrator/os/ubuntu-container-disk:22.04
            - image: gcr.io/spectro-images-public/release/virtual-machine-orchestrator/os/fedora-container-disk:37
            - image: gcr.io/spectro-images-public/release/virtual-machine-orchestrator/vlan-filtering/ubuntu:latest
            - image: gcr.io/spectro-images-public/release/spectro-cleanup:1.0.2
            - image: gcr.io/spectro-images-public/release/spectro-kubectl:1.30.2-spectro-4.4.a
    namespace: vm-dashboard
    palette:
        config:
            dashboard:
                access: private
    spectrocloud.com/install-priority: "20"
charts:
    virtual-machine-orchestrator:
        image:
            repository: gcr.io/spectro-images-public/release/spectro-vm-dashboard
            tag: "4.4.10"
        service:
            type: "ClusterIP"
        appConfig:
            clusterInfo:
                consoleBaseAddress: ""
        fullnameOverride: "virtual-machine-orchestrator"
        serviceAccount:
            # Specifies whether a service account should be created
            create: true
            # Annotations to add to the service account
            annotations: {}
            # The name of the service account to use.
            # If not set and create is true, a name is generated using the fullname template
            name: "virtual-machine-orchestrator"
        sampleTemplates:
            fedora37: false
            ubuntu2204: false
            ubuntu2204WithVol: false
            ubuntu2204staticIP: false
            fedora37staticIP: false
            # To create additional vm templates refer to https://docs.spectrocloud.com/vm-management/create-manage-vm/create-vm-template
        # This namespace will be used to store golden images
        goldenImagesNamespace: "vmo-golden-images"
        # These namespaces will be created and set up to deploy VMs into
        vmEnabledNamespaces:
            - "default"
            - "virtual-machines"
            - ns-adv
            - ns-edge
            - ns-product
            - ns-packs
        grafana:
            namespace: monitoring
        vlanFiltering:
            enabled: true
            namespace: kube-system
            image:
                repository: gcr.io/spectro-images-public/release/virtual-machine-orchestrator/vlan-filtering/ubuntu
                pullPolicy: IfNotPresent
                tag: "latest"
            env:
                # Which bridge interface to control
                bridgeIF: "br0"
                # Beginning of VLAN range to enable
                allowedVlans: "128,129"
                # Set to "true" to enable VLANs on the br0 interface for the host to use itself
                allowVlansOnSelf: "true"
                # Beginning of VLAN range to enable for use by the node itself
                allowedVlansOnSelf: "128,129"
        snapshot-controller:
            enabled: true
            replicas: 1
            # controller image and policies
            image:
                repository: registry.k8s.io/sig-storage/snapshot-controller
                pullPolicy: IfNotPresent
                tag: "v6.3.4"
            # A list/array of extra args that should be used 
            # when running the controller. Default args include log verbose level 
            # and leader election
            extraArgs: []
            # snapshot webhook config
            webhook:
                # all below values take effect only if webhook is enabled
                enabled: true
                # webhook controller image and policies
                image:
                    # change the image if you wish to use your own custom validation server image
                    repository: registry.k8s.io/sig-storage/snapshot-validation-webhook
                    pullPolicy: IfNotPresent
                    # Overrides the image tag whose default is the chart appVersion.
                    tag: "v6.3.4"
                validatingWebhook:
                    failurePolicy: Fail
                    timeoutSeconds: 2
                # Validating webhook is exposed on an HTTPS endpoint, and so
                # TLS certificate is required. This Helm chart relies on
                # cert-manager.io for managing TLS certificates.
                tls:
                    # If not empty, this issuer will be used to sign the certificate.
                    # If none is provided, a new, self-signing issuer will be created.
                    issuerRef: {}
                    # name: <ISSUER NAME>
                    # kind: <ClusterIssuer|Issuer>
                    # group: cert-manager.io

                    # Certificate duration. The generated certificate will be automatically
                    # renewed 1/3 of `certDuration` before its expiry.
                    # Value must be in units accepted by Go time.ParseDuration.
                    # See https://golang.org/pkg/time/#ParseDuration for allowed formats.
                    # Minimum accepted duration is `1h`.
                    # This option may be ignored/overridden by some issuer types.
                    certDuration: 8760h
                service:
                    # when running in cluster webhook service is recommended to be of type ClusterIP
                    type: ClusterIP
                    port: 443
                serviceAccount:
                    # Specifies whether a service account should be created.
                    create: true
                    # Annotations to add to the service account.
                    annotations: {}
                    # The name of the service account to use.
                    # If not set and create is true, a name is generated using the fullname template.
                    name: ""
                # Log verbosity level.
                # See https://github.com/kubernetes/community/blob/master/contributors/devel/sig-instrumentation/logging.md
                # for description of individual verbosity levels.
                logVerbosityLevel: 2
                podAnnotations: {}
                resources: {}
                nodeSelector: {}
                tolerations: []
                affinity: {}
                nameOverride: ""
                fullnameOverride: ""
            imagePullSecrets: []
            nameOverride: ""
            fullnameOverride: ""
            resources: {}
            # We usually recommend not to specify default resources and to leave this as a conscious
            # choice for the user. This also increases chances charts run on environments with little
            # resources, such as Minikube. If you do want to specify resources, uncomment the following
            # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
            # limits:
            #   cpu: 100m
            #   memory: 128Mi
            # requests:
            #   cpu: 100m
            #   memory: 128Mi

            nodeSelector: {}
            tolerations: []
            affinity: {}
            # create a default volume snapshot class
            volumeSnapshotClass:
                create: true
                name: "ceph-block-snapshot-class"
                driver: "rook-ceph.rbd.csi.ceph.com"
                # deletionPolicy determines whether a VolumeSnapshotContent created through
                # the VolumeSnapshotClass should be deleted when its bound VolumeSnapshot is deleted.
                # Supported values are "Retain" and "Delete".
                deletionPolicy: "Delete"
                # params is a key-value map with storage driver specific parameters for creating snapshots.
                params:
                    clusterID: rook-ceph
                    csi.storage.k8s.io/snapshotter-secret-name: csi-rbd-secret
                    csi.storage.k8s.io/snapshotter-secret-namespace: rook-ceph
                # key-value pair of extra labels to apply to the volumesnapshotclass
                extraLabels:
                    velero.io/csi-volumesnapshot-class: "true"
            # time for sleep hook in seconds
            hooksleepTime: 12
            # this install cert-manager latest version if not already installed
            cert-manager:
                enabled: false
                installCRDs: true
        kubevirt:
            enabled: true
            # defaults to kubevirt
            namespace: kubevirt
            namespaceLabels:
                pod-security.kubernetes.io/enforce: privileged
                pod-security.kubernetes.io/enforce-version: v{{ .spectro.system.kubernetes.version | substr 0 4 }}
            replicas: 1
            service:
                type: ClusterIP
                port: 443
                targetPort: 8443
            image:
                repository: gcr.io/spectro-images-public/release/kubevirt/virt-operator
                pullPolicy: IfNotPresent
                # Overrides the image tag whose default is the chart appVersion.
                tag: "v1.2.0"
            ## The Kubevirt CR that gets created
            kubevirtResource:
                name: kubevirt
                useEmulation: false
                # below gates are required for virtual machine orchestrator pack, users can append additional gates
                additionalFeatureGates:
                    - LiveMigration
                    - HotplugVolumes
                    - Snapshot
                    - VMExport
                    - ExpandDisks
                    - HotplugNICs
                    - VMLiveUpdateFeatures
                    - VMPersistentState
                    - Sidecar
                    - VolumeMigration
                    - CPUManager                    
                    # for additional feature gates refer to https://docs.spectrocloud.com/vm-management#featuregates
                config:
                    evictionStrategy: "LiveMigrate"
                    # additionalConfig lets you define any configuration other than developerConfiguration and evictionStrategy
                    additionalConfig:
                        vmStateStorageClass: "ceph-filesystem"
                    # additionalDevConfig lets you define dev config other than emulation and feature gate
                    additionalDevConfig: {}
                    # vmRolloutStrategy lets you define how changes to a VM object propagate to its VMI objects
                    vmRolloutStrategy: LiveUpdate
                certificateRotateStrategy: {}
                customizeComponents:
                # flags:
                #   api:
                #     v: 
                #       "5"
                #     port:
                #       "8443"  
                imagePullPolicy: IfNotPresent
                infra: {}
                # The name of the Prometheus service account that needs read-access to KubeVirt endpoints
                monitorAccount: "prometheus-operator-prometheus"
                # The namespace Prometheus is deployed in
                monitorNamespace: "monitoring"
                # The namespace the service monitor will be deployed. Either specify this or the monitorNamespace
                serviceMonitorNamespace: "monitoring"
                workloads: {}
                workloadsUpdateStrategy:
                    workloadUpdateMethods:
                        - LiveMigrate
                # uninstallStrategy to use, options are RemoveWorkloads, BlockUninstallIfWorkloadsExist 
                uninstallStrategy: ""
            ingress:
                enabled: true
                ingressClassName: nginx
                annotations:
                    cert-manager.io/issuer: kubevirt-selfsigned-issuer
                    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
                labels: {}
                hosts:
                    - host: virt-exportproxy.maas-eng.sc
                      paths:
                        - path: /
                          pathType: ImplementationSpecific
                tls:
                    - secretName: virt-exportproxy-tls
                      hosts:
                        - virt-exportproxy.maas-eng.sc
                        #   - secretName: chart-example-tls
                        #     hosts:
                        #       - virt-exportproxy.maas.sc
        cdi:
            enabled: true
            namespaceLabels:
                pod-security.kubernetes.io/enforce: privileged
                pod-security.kubernetes.io/enforce-version: v{{ .spectro.system.kubernetes.version | substr 0 4 }}
            replicas: 1
            image:
                repository: quay.io/kubevirt/cdi-operator
                pullPolicy: IfNotPresent
                # Overrides the image tag whose default is the chart appVersion.
                tag: "v1.58.0"
            service:
                type: ClusterIP
                port: 443
                targetPort: 8443
            # set enabled to true and add private registry details to bring up VMs in airgap environment
            privateRegistry:
                enabled: false
                registryIP: #Ex: 10.10.225.20
                registryBasePath: #Ex: specto-images
            ## The CDI CR that gets created
            cdiResource:
                additionalFeatureGates:
                # - FeatureName
                additionalConfig:
                    podResourceRequirements:
                        requests:
                            cpu: 1
                            memory: 2G
                        limits:
                            cpu: 2
                            memory: 8G
                    filesystemOverhead:
                        global: "0.055"
                        storageClass:
                            spectro-storage-class: "0.1"
                            #insecureRegistries: [] # List of insecure registries to allow in the CDI importer, preffered in air-gapped environments
                            #importProxy:
                            #  HTTPProxy: "http://username:password@your-proxy-server:3128"
                            #  HTTPSProxy: "http://username:password@your-proxy-server:3128"
                            #  noProxy: "127.0.0.1,localhost,10.0.0.0/8,172.16.0.0/12,192.168.0.0/16,.company.local"
                            #  TrustedCAProxy: configmap-name # optional: the ConfigMap name of a user-provided trusted certificate authority (CA) bundle to be added to the importer pod CA bundle
            ingress:
                enabled: true
                className: "nginx"
                annotations:
                    cert-manager.io/issuer: cdi-selfsigned-issuer
                    nginx.ingress.kubernetes.io/proxy-body-size: "0"
                    nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
                    nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
                    nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
                    nginx.ingress.kubernetes.io/backend-protocol: "HTTPS"
                hosts:
                    - host: cdi-uploadproxy.maas-eng.sc
                      paths:
                        - path: /
                          pathType: ImplementationSpecific
                tls:
                    - secretName: cdi-uploadproxy-tls
                      hosts:
                        - cdi-uploadproxy.maas-eng.sc
                        #  - secretName: chart-example-tls
                        #    hosts:
                        #      - cdi-uploadproxy.maas.sc
        multus:
            enabled: true
            image:
                repository: ghcr.io/k8snetworkplumbingwg/multus-cni
                pullPolicy: IfNotPresent
                # Overrides the image tag whose default is the chart appVersion.
                tag: "v4.0.2-thick"
            networkController:
                criSocket:
                    enableK3SHostPath: false # true for K3S and RKE2, false for PXK-E
                    criSocketContainerPath: /host/run/containerd/containerd.sock
            imagePullSecrets: []
            podAnnotations: {}
            nodeSelector: {}
            affinity: {}
            dpdkCompatibility: false
            cleanup:
                image: gcr.io/spectro-images-public/release/spectro-cleanup
                tag: "1.0.2"
            networkAttachDef:
                create: false
                # a json string to apply
                config: ''
                # a sample config 
                # '{
                #   "cniVersion": "0.3.0",
                #   "type": "macvlan",
                #   "master": "ens5",
                #   "mode": "bridge",
                #   "ipam": {
                #     "type": "host-local",
                #     "subnet": "192.168.1.0/24",
                #     "rangeStart": "192.168.1.200",
                #     "rangeEnd": "192.168.1.216",
                #     "routes": [
                #       { "dst": "0.0.0.0/0" }
                #     ],
                #     "gateway": "192.168.1.1"
                #   }
                # }'
        descheduler:
            enabled: true
            namespace: "kube-system"
            # CronJob or Deployment
            kind: CronJob
            image:
                repository: registry.k8s.io/descheduler/descheduler
                # Overrides the image tag whose default is the chart version
                tag: "v0.30.1"
                pullPolicy: IfNotPresent
            imagePullSecrets:
            #   - name: container-registry-secret
            resources:
                requests:
                    cpu: 500m
                    memory: 256Mi
                limits:
                    cpu: 500m
                    memory: 256Mi
            securityContext:
                allowPrivilegeEscalation: false
                capabilities:
                    drop:
                        - ALL
                privileged: false
                readOnlyRootFilesystem: true
                runAsNonRoot: true
                runAsUser: 1000
            # podSecurityContext -- [Security context for pod](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/)
            podSecurityContext: {}
            # fsGroup: 1000

            nameOverride: ""
            fullnameOverride: "descheduler"
            # labels that'll be applied to all resources
            commonLabels: {}
            cronJobApiVersion: "batch/v1"
            schedule: "*/2 * * * *"
            suspend: false
            # startingDeadlineSeconds: 200
            # successfulJobsHistoryLimit: 3
            # failedJobsHistoryLimit: 1
            # ttlSecondsAfterFinished 600
            # timeZone: Etc/UTC

            # Required when running as a Deployment
            deschedulingInterval: 5m
            # Specifies the replica count for Deployment
            # Set leaderElection if you want to use more than 1 replica
            # Set affinity.podAntiAffinity rule if you want to schedule onto a node
            # only if that node is in the same zone as at least one already-running descheduler
            replicas: 1
            # Specifies whether Leader Election resources should be created
            # Required when running as a Deployment
            # NOTE: Leader election can't be activated if DryRun enabled
            leaderElection: {}
            #  enabled: true
            #  leaseDuration: 15s
            #  renewDeadline: 10s
            #  retryPeriod: 2s
            #  resourceLock: "leases"
            #  resourceName: "descheduler"
            #  resourceNamescape: "kube-system"

            command:
                - "/bin/descheduler"
            cmdOptions:
                v: 3
            # Recommended to use the latest Policy API version supported by the Descheduler app version
            deschedulerPolicyAPIVersion: "descheduler/v1alpha2"
            deschedulerPolicy:
                # nodeSelector: "key1=value1,key2=value2"
                # maxNoOfPodsToEvictPerNode: 10
                # maxNoOfPodsToEvictPerNamespace: 10
                # ignorePvcPods: true
                # evictLocalStoragePods: true
                # evictDaemonSetPods: true
                # tracing:
                #   collectorEndpoint: otel-collector.observability.svc.cluster.local:4317
                #   transportCert: ""
                #   serviceName: ""
                #   serviceNamespace: ""
                #   sampleRate: 1.0
                #   fallbackToNoOpProviderOnError: true
                profiles:
                    - name: default
                      pluginConfig:
                        - name: DefaultEvictor
                          args:
                            ignorePvcPods: true
                            evictLocalStoragePods: true
                        - name: RemoveDuplicates
                        - name: RemovePodsHavingTooManyRestarts
                          args:
                            podRestartThreshold: 100
                            includingInitContainers: true
                        - name: RemovePodsViolatingNodeAffinity
                          args:
                            nodeAffinityType:
                                - requiredDuringSchedulingIgnoredDuringExecution
                        - name: RemovePodsViolatingNodeTaints
                        - name: RemovePodsViolatingInterPodAntiAffinity
                        - name: RemovePodsViolatingTopologySpreadConstraint
                        - name: LowNodeUtilization
                          args:
                            thresholds:
                                cpu: 20
                                memory: 20
                                pods: 20
                            targetThresholds:
                                cpu: 50
                                memory: 50
                                pods: 50
                      plugins:
                        balance:
                            enabled:
                                - RemoveDuplicates
                                - RemovePodsViolatingTopologySpreadConstraint
                                - LowNodeUtilization
                        deschedule:
                            enabled:
                                - RemovePodsHavingTooManyRestarts
                                - RemovePodsViolatingNodeTaints
                                - RemovePodsViolatingNodeAffinity
                                - RemovePodsViolatingInterPodAntiAffinity
            priorityClassName: system-cluster-critical
            nodeSelector: {}
            #  foo: bar

            affinity: {}
            # nodeAffinity:
            #   requiredDuringSchedulingIgnoredDuringExecution:
            #     nodeSelectorTerms:
            #     - matchExpressions:
            #       - key: kubernetes.io/e2e-az-name
            #         operator: In
            #         values:
            #         - e2e-az1
            #         - e2e-az2
            #  podAntiAffinity:
            #    requiredDuringSchedulingIgnoredDuringExecution:
            #      - labelSelector:
            #          matchExpressions:
            #            - key: app.kubernetes.io/name
            #              operator: In
            #              values:
            #                - descheduler
            #        topologyKey: "kubernetes.io/hostname"
            topologySpreadConstraints: []
            # - maxSkew: 1
            #   topologyKey: kubernetes.io/hostname
            #   whenUnsatisfiable: DoNotSchedule
            #   labelSelector:
            #     matchLabels:
            #       app.kubernetes.io/name: descheduler
            tolerations: []
            # - key: 'management'
            #   operator: 'Equal'
            #   value: 'tool'
            #   effect: 'NoSchedule'

            rbac:
                # Specifies whether RBAC resources should be created
                create: true
            serviceAccount:
                # Specifies whether a ServiceAccount should be created
                create: true
                # The name of the ServiceAccount to use.
                # If not set and create is true, a name is generated using the fullname template
                name:
                # Specifies custom annotations for the serviceAccount
                annotations: {}
            podAnnotations: {}
            podLabels: {}
            dnsConfig: {}
            livenessProbe:
                failureThreshold: 3
                httpGet:
                    path: /healthz
                    port: 10258
                    scheme: HTTPS
                initialDelaySeconds: 3
                periodSeconds: 10
            service:
                enabled: false
                # @param service.ipFamilyPolicy [string], support SingleStack, PreferDualStack and RequireDualStack
                #
                ipFamilyPolicy: ""
                # @param service.ipFamilies [array] List of IP families (e.g. IPv4, IPv6) assigned to the service.
                # Ref: https://kubernetes.io/docs/concepts/services-networking/dual-stack/
                # E.g.
                # ipFamilies:
                #   - IPv6
                #   - IPv4
                ipFamilies: []
            serviceMonitor:
                enabled: false
                # The namespace where Prometheus expects to find service monitors.
                # namespace: ""
                # Add custom labels to the ServiceMonitor resource
                additionalLabels: {}
                # prometheus: kube-prometheus-stack
                interval: ""
                # honorLabels: true
                insecureSkipVerify: true
                serverName: null
                metricRelabelings: []
                # - action: keep
                #   regex: 'descheduler_(build_info|pods_evicted)'
                #   sourceLabels: [__name__]
                relabelings: []
                # - sourceLabels: [__meta_kubernetes_pod_node_name]
                #   separator: ;
                #   regex: ^(.*)$
                #   targetLabel: nodename
                #   replacement: $1
                #   action: replace
